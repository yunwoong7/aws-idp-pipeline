"""
Document Summarizer Lambda
Combines all segment content_combined to generate document-level summary using LLM
"""

import json
import logging
import os
from typing import Dict, Any, List
from datetime import datetime, timezone

# Common module imports
from common import (
    DynamoDBService,
    OpenSearchService,
    handle_lambda_error,
    get_current_timestamp
)

# Logging setup
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize common services
db_service = DynamoDBService()
opensearch_service = OpenSearchService()

def lambda_handler(event: Dict[str, Any], context) -> Dict[str, Any]:
    """
    Document Summarizer Lambda handler
    Generate document-level summary from all segment content_combined using LLM
    
    Args:
        event: Event received from Step Function (includes document_id and index_id)
        context: Lambda context
        
    Returns:
        Processing result
    """
    try:
        logger.info(f"Document Summarizer started - Event: {json.dumps(event, ensure_ascii=False, indent=2)}")
        
        # Extract input data
        index_id = event.get('index_id')
        document_id = event.get('document_id')
        
        if not document_id or not index_id:
            raise ValueError("Both document_id and index_id are required.")
        
        logger.info(f"ğŸ“‹ Target: index_id={index_id}, document_id={document_id}")
        
        # Generate document summary
        summary_result = generate_document_summary(document_id, index_id)
        
        if summary_result:
            logger.info(f"âœ… Document summary generation complete: {document_id}")
            
            # Update document status to final completion
            update_document_final_status(document_id, True)
            
            return {
                'success': True,
                'message': 'Document summary generation complete',
                'document_id': document_id,
                'index_id': index_id,
                'summary_length': len(summary_result.get('summary', ''))
            }
        else:
            logger.error(f"âŒ Document summary generation failed: {document_id}")
            
            # Update document status to indicate failure
            update_document_final_status(document_id, False)
            
            return {
                'success': False,
                'message': 'Document summary generation failed',
                'document_id': document_id,
                'index_id': index_id
            }
        
    except Exception as e:
        logger.error(f"Document Summarizer error: {str(e)}", exc_info=True)
        return handle_lambda_error(e)

def generate_document_summary(document_id: str, index_id: str) -> Dict[str, Any]:
    """Generate document-level summary from all segments"""
    try:
        logger.info(f"ğŸ“„ Document summary generation started: {document_id}")
        
        # Get document information
        document = db_service.get_item('documents', {'document_id': document_id})
        if not document:
            logger.error(f"âŒ Document not found: {document_id}")
            return None
        
        media_type = document.get('media_type', 'DOCUMENT')
        file_name = document.get('file_name', 'Unknown')
        
        logger.info(f"ğŸ“„ Document info: {file_name} ({media_type})")
        
        # Retrieve all segments for the document
        from boto3.dynamodb.conditions import Key
        segments_response = db_service.query_items(
            table_name='segments',
            key_condition_expression=Key('document_id').eq(document_id),
            index_name='DocumentIdIndex'
        )
        
        segments = segments_response.get('Items', [])
        logger.info(f"ğŸ“‹ Total segments found: {len(segments)}")
        
        if not segments:
            logger.warning(f"âš ï¸ No segments found for document: {document_id}")
            return None
        
        # Collect content_combined from all segments
        segment_contents = []
        
        for segment in segments:
            segment_id = segment.get('segment_id')
            segment_index = segment.get('segment_index', 0)
            segment_type = segment.get('segment_type', 'PAGE')
            
            if not segment_id:
                continue
            
            # Get segment document from OpenSearch
            segment_doc = opensearch_service.get_segment_document(index_id, segment_id)
            
            if segment_doc and segment_doc.get('content_combined'):
                content_combined = segment_doc['content_combined']
                
                segment_contents.append({
                    'segment_index': segment_index,
                    'segment_type': segment_type,
                    'content_combined': content_combined
                })
                
                logger.debug(f"ğŸ“„ Segment {segment_index} content collected: {len(content_combined)} chars")
        
        if not segment_contents:
            logger.warning(f"âš ï¸ No content_combined found for document: {document_id}")
            return None
        
        # Sort by segment_index
        segment_contents.sort(key=lambda x: x['segment_index'])
        
        logger.info(f"ğŸ“Š Total segments with content: {len(segment_contents)}")
        
        # Generate LLM prompt based on media type
        combined_content = create_combined_content_for_llm(segment_contents, media_type, file_name)
        
        # Generate summary using LLM
        summary = generate_summary_with_llm(combined_content, media_type, file_name)
        
        if summary:
            # Update Documents table with summary
            success = update_document_summary(document_id, summary)
            
            if success:
                return {
                    'summary': summary,
                    'segment_count': len(segment_contents),
                    'total_content_length': sum(len(s['content_combined']) for s in segment_contents)
                }
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ Document summary generation error: {str(e)}")
        raise

def create_combined_content_for_llm(segment_contents: List[Dict[str, Any]], media_type: str, file_name: str) -> str:
    """Create combined content for LLM input"""
    try:
        content_parts = []
        
        # Add header based on media type
        if media_type == 'VIDEO':
            content_parts.append(f"# ë™ì˜ìƒ '{file_name}' ì „ì²´ ë¶„ì„ ë‚´ìš©\n")
            content_parts.append(f"ë‹¤ìŒì€ {len(segment_contents)}ê°œ ì±•í„°ë³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n")
        else:
            content_parts.append(f"# ë¬¸ì„œ '{file_name}' ì „ì²´ ë¶„ì„ ë‚´ìš©\n")
            content_parts.append(f"ë‹¤ìŒì€ {len(segment_contents)}ê°œ í˜ì´ì§€ë³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n")
        
        # Add each segment's content
        for segment in segment_contents:
            segment_index = segment['segment_index']
            segment_type = segment['segment_type']
            content_combined = segment['content_combined']
            
            if media_type == 'VIDEO':
                content_parts.append(f"## ì±•í„° {segment_index + 1}\n")
            else:
                content_parts.append(f"## í˜ì´ì§€ {segment_index + 1}\n")
            
            content_parts.append(f"{content_combined}\n\n")
        
        combined_content = "\n".join(content_parts)
        
        logger.info(f"ğŸ“ Combined content for LLM: {len(combined_content)} chars")
        return combined_content
        
    except Exception as e:
        logger.error(f"âŒ Error creating combined content: {str(e)}")
        return ""

def generate_summary_with_llm(content: str, media_type: str, file_name: str) -> str:
    """Generate summary using LLM (Bedrock)"""
    try:
        import boto3
        
        # Get Bedrock configuration
        model_id = os.environ.get('BEDROCK_SUMMARY_MODEL_ID', 'anthropic.claude-3-5-sonnet-20241022-v2:0')
        max_tokens = int(os.environ.get('BEDROCK_SUMMARY_MAX_TOKENS', '4000'))
        
        bedrock_runtime = boto3.client('bedrock-runtime')
        
        # Create prompt based on media type
        if media_type == 'VIDEO':
            system_prompt = f"""ë‹¹ì‹ ì€ ë™ì˜ìƒ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë™ì˜ìƒ '{file_name}'ì˜ ì±•í„°ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ë™ì˜ìƒì˜ ì¢…í•©ì ì¸ ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìš”ì•½ì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ë™ì˜ìƒ ì „ì²´ ê°œìš” (ì£¼ì œ, ëª©ì , ëŒ€ìƒ ë“±)
2. ì£¼ìš” ë‚´ìš© ë° í•µì‹¬ ë©”ì‹œì§€
3. ì±•í„°ë³„ ìš”ì  ì •ë¦¬
4. ê²°ë¡  ë° ì‹œì²­ìì—ê²Œ ì „ë‹¬í•˜ê³ ì í•˜ëŠ” ë©”ì‹œì§€

ì „ë¬¸ì ì´ê³  ì²´ê³„ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            user_prompt = f"ë‹¤ìŒì€ ë™ì˜ìƒ '{file_name}'ì˜ ì±•í„°ë³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ë™ì˜ìƒì˜ ì¢…í•© ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n{content}"
        else:
            system_prompt = f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œ '{file_name}'ì˜ í˜ì´ì§€ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ë¬¸ì„œì˜ ì¢…í•©ì ì¸ ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìš”ì•½ì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ë¬¸ì„œ ì „ì²´ ê°œìš” (ì£¼ì œ, ëª©ì , ëŒ€ìƒ ë“±)
2. ì£¼ìš” ë‚´ìš© ë° í•µì‹¬ í¬ì¸íŠ¸
3. í˜ì´ì§€ë³„ ì¤‘ìš” ì‚¬í•­ ì •ë¦¬
4. ê²°ë¡  ë° ë¬¸ì„œì˜ í•µì‹¬ ë©”ì‹œì§€

ì „ë¬¸ì ì´ê³  ì²´ê³„ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            user_prompt = f"ë‹¤ìŒì€ ë¬¸ì„œ '{file_name}'ì˜ í˜ì´ì§€ë³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ë¬¸ì„œì˜ ì¢…í•© ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n{content}"
        
        # Prepare request body
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": max_tokens,
            "system": system_prompt,
            "messages": [
                {
                    "role": "user",
                    "content": user_prompt
                }
            ]
        }
        
        # Call Bedrock
        logger.info(f"ğŸ¤– Calling Bedrock model: {model_id}")
        response = bedrock_runtime.invoke_model(
            modelId=model_id,
            body=json.dumps(request_body)
        )
        
        # Parse response
        response_body = json.loads(response['body'].read())
        summary = response_body['content'][0]['text']
        
        logger.info(f"âœ… LLM summary generated: {len(summary)} chars")
        return summary
        
    except Exception as e:
        logger.error(f"âŒ LLM summary generation error: {str(e)}")
        return ""

def update_document_summary(document_id: str, summary: str) -> bool:
    """Update Documents table with generated summary"""
    try:
        current_time = get_current_timestamp()
        
        update_response = db_service.update_item(
            table_name='documents',
            key={'document_id': document_id},
            update_expression='SET summary = :summary, updated_at = :updated_at',
            expression_attribute_values={
                ':summary': summary,
                ':updated_at': current_time
            }
        )
        
        logger.info(f"ğŸ“„ Document summary updated: {document_id} ({len(summary)} chars)")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Document summary update failed: {str(e)}")
        return False

def update_document_final_status(document_id: str, success: bool) -> None:
    """Update document status to final completion"""
    try:
        current_time = get_current_timestamp()
        final_status = 'completed' if success else 'summary_failed'
        
        update_response = db_service.update_item(
            table_name='documents',
            key={'document_id': document_id},
            update_expression='SET #status = :status, updated_at = :updated_at',
            expression_attribute_names={'#status': 'status'},
            expression_attribute_values={
                ':status': final_status,
                ':updated_at': current_time
            }
        )
        
        logger.info(f"ğŸ“„ Document final status update: {document_id} -> {final_status}")
        
    except Exception as e:
        logger.error(f"âŒ Document status update failed: {str(e)}")

# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    test_event = {
        "index_id": "test_index_123",
        "document_id": "test_document_456"
    }
    
    result = lambda_handler(test_event, None)
    print(json.dumps(result, ensure_ascii=False, indent=2))