"""
LangGraph Model Node - AI model calling
"""

import logging
import time
import os
import sys
from datetime import datetime, timezone
from typing import Dict, Any, List, Tuple
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langgraph.checkpoint.memory import MemorySaver

# Common module imports
sys.path.append('/opt/python')

from agent.state.agent_state import AgentState
from prompts import prompt_manager

logger = logging.getLogger(__name__)
memory = MemorySaver()


class ModelNode:
    """
    LangGraph Model Node - AI ëª¨ë¸ í˜¸ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ë…¸ë“œ
    """
    
    def __init__(self, model, tools):
        """
        Args:
            model: LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸
        """
        self.model = model
        self.tools = tools
        logger.info(f"ğŸ¤– ModelNode ì´ˆê¸°í™” ì™„ë£Œ - ë„êµ¬: {len(tools)}ê°œ")
        
    
    def __call__(self, state: AgentState, config: RunnableConfig) -> AgentState:
        """
        ëª¨ë¸ ë…¸ë“œ ì‹¤í–‰
        
        Args:
            state: LangGraph AgentState
            config: ì‹¤í–‰ êµ¬ì„±
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ AgentState
        """
        logger.info("=== ğŸ¤– MODEL NODE ì‹¤í–‰ ===")
        
        # ì…ë ¥ ìƒíƒœ ë¡œê¹…
        self._log_input_state(state)
        
        # ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸
        user_query = self._extract_user_query(state)
        
        # í˜„ì¬ ë‹¨ê³„ ì¦ê°€ - ìƒì„¸ ë¡œê¹… ì¶”ê°€
        current_step_before = state.get('current_step', 0)
        current_step = current_step_before + 1
        max_iterations = state.get('max_iterations', 10)
        
        # ë‹¨ê³„ ì¦ê°€ ë¡œê¹…
        logger.info("ğŸ”¢ STEP INCREMENT ìƒì„¸ ì •ë³´:")
        logger.info(f"  - ì´ì „ ë‹¨ê³„: {current_step_before}")
        logger.info(f"  - í˜„ì¬ ë‹¨ê³„: {current_step}")
        logger.info(f"  - ìµœëŒ€ ë°˜ë³µ: {max_iterations}")
        logger.info(f"  - ì œí•œ í™•ì¸: {current_step} >= {max_iterations} = {current_step >= max_iterations}")
        
        state['current_step'] = current_step
        
        # MAX_ITERATIONS ì²´í¬
        if current_step >= max_iterations:
            logger.info("ğŸ”„ MAX_ITERATIONS ë„ë‹¬ - ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±")
            
            # ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±
            final_response = self._generate_comprehensive_final_analysis(state, current_step, max_iterations)
            
            # ê°•ì œ ì¢…ë£Œë¥¼ ìœ„í•œ AIMessage ìƒì„± (tool_calls ì—†ìŒ)
            from langchain_core.messages import AIMessage
            final_message = AIMessage(content=final_response)
            
            updated_state = {
                **state,
                'current_step': current_step,
                'messages': state.get('messages', []) + [final_message],
                'max_iterations_reached': True
            }
            
            logger.info("âœ… MAX_ITERATIONS ì¢…í•© ë¶„ì„ ì™„ë£Œ")
            return updated_state
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_data = self._create_prompt(state, user_query)
        
        # ë©”ì‹œì§€ ì¤€ë¹„
        prompt_messages = self._prepare_messages(state, prompt_data)
        
        # ëª¨ë¸ í˜¸ì¶œ
        response = self._invoke_model(prompt_messages, config, state)
        
        # ì‘ë‹µ ë¡œê¹…
        self._log_model_response(response, current_step)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ (ModelNodeëŠ” messagesì™€ current_stepë§Œ ì—…ë°ì´íŠ¸)
        updated_state = {
            **state,
            "messages": response["messages"],
            "user_query": user_query,
            "current_step": current_step
        }
        
        # State ì¶”ì  ì •ë³´ ë¡œê¹…
        logger.info(f"ğŸ¤– MODEL NODE ì™„ë£Œ - Step {current_step}")
        logger.info(f"ğŸ“Š ì—…ë°ì´íŠ¸ëœ Stateì˜ current_step: {updated_state.get('current_step')}")
        logger.info(f"ğŸ“Š ì—…ë°ì´íŠ¸ëœ Stateì˜ max_iterations: {updated_state.get('max_iterations')}")
        
        # ë©”ì‹œì§€ ì •ë³´ ë¡œê¹…
        last_message = updated_state["messages"][-1] if updated_state["messages"] else None
        if last_message:
            has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls
            logger.info(f"ğŸ“¨ ë§ˆì§€ë§‰ ë©”ì‹œì§€: {type(last_message).__name__}, tool_calls={has_tool_calls}")
        
        return updated_state
    
    def _log_input_state(self, state: AgentState):
        """ì…ë ¥ ìƒíƒœ ë¡œê¹…"""
        logger.info(f"ğŸ“¥ ì…ë ¥ - Index: {state.get('index_id')}, Document: {state.get('document_id')}")
        logger.info(f"ğŸ“¥ ì…ë ¥ - Messages: {len(state.get('messages', []))}ê°œ")
        logger.info(f"ğŸ“¥ ì…ë ¥ - Step: {state.get('current_step', 0)}")
        logger.info(f"ğŸ“¥ ì…ë ¥ - Max Iterations: {state.get('max_iterations', 'Not Set')}")
        
        # ë¶„ì„ ì´ë ¥ ë¡œê¹…
        analysis_history = state.get('analysis_history', [])
        if analysis_history:
            logger.info(f"ğŸ“Š ë¶„ì„ ì´ë ¥: {len(analysis_history)}ê°œ")
            for i, entry in enumerate(analysis_history[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ
                tool_name = entry.get('tool_name', 'Unknown')
                success = 'âœ…' if entry.get('success') else 'âŒ'
                logger.info(f"  {i}. {success} {tool_name}")
    
    def _extract_user_query(self, state: AgentState) -> str:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ"""
        user_query = state.get('user_query', '')
        if not user_query:
            # messagesì—ì„œ ì¶”ì¶œ
            for msg in state.get('messages', []):
                if isinstance(msg, HumanMessage):
                    user_query = self._normalize_content(msg.content)
                    break
        
        logger.info(f"ğŸ’¬ ì‚¬ìš©ì ì¿¼ë¦¬: {user_query[:100]}...")
        return user_query
    
    def _create_prompt(self, state: AgentState, user_query: str) -> Dict[str, str]:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # Stateì—ì„œ í˜„ì¬ ë‹¨ê³„ ë° ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘
        current_step = state.get('current_step', 0)
        combined_context = state.get('combined_analysis_context', '')
        previous_context = state.get('previous_analysis_context', '')
        analysis_history = state.get('analysis_history', [])
        index_id = state.get('index_id', 'unknown')
        
        # ìƒˆë¡œ ì¶”ê°€: ì°¸ì¡° ì •ë³´ ë° ë„êµ¬ ì»¨í…ì¸  ìˆ˜ì§‘
        tool_references = state.get('tool_references', [])
        tool_content = state.get('tool_content', '')
        
        # ë””ë²„ê¹… ë¡œê·¸
        logger.info(f"ğŸ” _create_prompt ë””ë²„ê¹…:")
        logger.info(f"  - current_step: {current_step}")
        logger.info(f"  - combined_context ê¸¸ì´: {len(combined_context)}")
        logger.info(f"  - previous_context ê¸¸ì´: {len(previous_context)}")
        logger.info(f"  - analysis_history ê°œìˆ˜: {len(analysis_history)}")
        logger.info(f"  - tool_references ê°œìˆ˜: {len(tool_references)}")
        logger.info(f"  - tool_content ê¸¸ì´: {len(tool_content)}")
        
        # combined_context ì„¤ì • (ToolNodeì—ì„œ ì—…ë°ì´íŠ¸ëœ ê²°ê³¼ ì‚¬ìš©)
        if not combined_context or combined_context.strip() == "":
            combined_context = "ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
        
        # ì°¸ì¡° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        references_text = ""
        if tool_references:
            ref_lines = []
            for i, ref in enumerate(tool_references, 1):
                title = ref.get('title', f'ì°¸ì¡° {i}')
                value = ref.get('value', '')
                ref_lines.append(f"[{i}] {title}: {value}")
            references_text = "\n".join(ref_lines)
            logger.info(f"ğŸ“‹ ì°¸ì¡° ì •ë³´ ìƒì„±: {len(references_text)}ì, {len(tool_references)}ê°œ í•­ëª©")
        
        # ë„êµ¬ ì»¨í…ì¸ ê°€ ìˆìœ¼ë©´ combined_contextì— ì¶”ê°€
        if tool_content and tool_content.strip():
            if combined_context and combined_context != "ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ":
                combined_context = f"{combined_context}\n\n=== ìµœê·¼ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ===\n{tool_content}"
            else:
                combined_context = f"=== ìµœê·¼ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ===\n{tool_content}"
            logger.info(f"ğŸ“ ë„êµ¬ ì»¨í…ì¸ ë¥¼ combined_contextì— ì¶”ê°€: {len(tool_content)}ì")
        
        # ìµœì¢… ë¶„ì„ ë‚´ìš© ë¡œê¹…
        if combined_context:
            logger.info(f"ğŸ“‹ ìµœì¢… PREVIOUS_ANALYSIS ê¸¸ì´: {len(combined_context)}")
            logger.info(f"ğŸ“‹ PREVIOUS_ANALYSIS ë¯¸ë¦¬ë³´ê¸°: {combined_context[:300]}...")
        else:
            logger.info("ğŸ“‹ PREVIOUS_ANALYSISê°€ ë¹„ì–´ìˆìŒ")
        
        prompt_data = prompt_manager.get_prompt(
            "agent_profile", 
            DATETIME=datetime.now(tz=timezone.utc).isoformat(),
            INDEX_ID=index_id,
            QUERY=user_query,
            PREVIOUS_ANALYSIS=combined_context if combined_context else "ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ",
            REFERENCES=references_text if references_text else "ì°¸ì¡° ì •ë³´ ì—†ìŒ",
            MEDIA_TYPE=state.get('media_type', 'DOCUMENT')
        )
        
        logger.info(f">>>>>>>>> PROMPT ìƒì„± (ë‹¨ê³„ {current_step}) >>>>>>>>>")
        logger.info(f"System Prompt ê¸¸ì´: {len(prompt_data.get('system_prompt', ''))}")
        logger.info(f"Instruction ê¸¸ì´: {len(prompt_data.get('instruction', ''))}")
        logger.info(f"ì „ì²´ í”„ë¡¬í”„íŠ¸ ë‚´ìš©:")
        logger.info(prompt_data)
        logger.info(f"<<<<<<<<< PROMPT ì™„ë£Œ (ë‹¨ê³„ {current_step}) <<<<<<<<<<<")

        logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"  - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: {len(prompt_data['system_prompt'])} ë¬¸ì")
        logger.info(f"  - ì¸ìŠ¤íŠ¸ëŸ­ì…˜: {len(prompt_data.get('instruction', ''))} ë¬¸ì")
        logger.info(f"  - ë¶„ì„ ì»¨í…ìŠ¤íŠ¸: {len(combined_context)} ë¬¸ì")
        
        # ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ë‚´ìš© ìš”ì•½ ë¡œê¹… (ê°œë°œìš©)
        if combined_context:
            preview = combined_context[:200] + "..." if len(combined_context) > 200 else combined_context
            logger.info(f"ğŸ“‹ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {preview}")
        
        return prompt_data
    
    def _prepare_messages(self, state: AgentState, prompt_data: Dict[str, str]) -> list:
        """ë©”ì‹œì§€ ì¤€ë¹„"""
        messages = state.get('messages', [])
        non_system_messages = [msg for msg in messages if not isinstance(msg, SystemMessage)]
        
        prompt_messages = [
            SystemMessage(content=prompt_data["system_prompt"])
        ]
        
        if "instruction" in prompt_data:
            prompt_messages.append(HumanMessage(content=prompt_data["instruction"]))
        
        prompt_messages.extend(non_system_messages)
        
        logger.info(f"ğŸ“¨ ë©”ì‹œì§€ ì¤€ë¹„ ì™„ë£Œ: {len(prompt_messages)}ê°œ")
        return prompt_messages
    
    def _invoke_model(self, prompt_messages: list, config, state: 'AgentState' = None) -> Dict[str, Any]:
        """ëª¨ë¸ í˜¸ì¶œ - ìˆœìˆ˜ LLM í˜¸ì¶œë§Œ ë‹´ë‹¹"""
        current_step = state.get('current_step', 0) if state else 0
        logger.info(f"ğŸ”„ AI ëª¨ë¸ í˜¸ì¶œ ì‹œì‘ (ë‹¨ê³„ {current_step})...")
        
        # ë„êµ¬ë¥¼ ë°”ì¸ë”©í•œ ëª¨ë¸ ìƒì„±
        model_with_tools = self.model.bind_tools(self.tools)
        
        # ì§ì ‘ LLM í˜¸ì¶œ
        response_message = model_with_tools.invoke(prompt_messages)
        
        logger.info(f"âœ… AI ëª¨ë¸ ì‘ë‹µ ì™„ë£Œ")
        
        # ì‘ë‹µ ë©”ì‹œì§€ í™•ì¸
        if hasattr(response_message, 'tool_calls') and response_message.tool_calls:
            tool_names = [tc.get('name', 'Unknown') for tc in response_message.tool_calls]
            logger.info(f"ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ ì˜ˆì •: {tool_names}")
        else:
            logger.info("ğŸ’¬ ìµœì¢… ì‘ë‹µ ìƒì„± (ë„êµ¬ í˜¸ì¶œ ì—†ìŒ)")
        
        # ê¸°ì¡´ ë©”ì‹œì§€ì— ìƒˆ ì‘ë‹µ ì¶”ê°€
        updated_messages = state.get('messages', []) + [response_message]
        
        # ì‘ë‹µ êµ¬ì¡° ìƒì„± (ê¸°ì¡´ messagesë¥¼ ëª¨ë‘ í¬í•¨)
        response = {
            "messages": updated_messages
        }
        
        return response
    
    def _log_model_response(self, response: Dict[str, Any], current_step: int):
        """ëª¨ë¸ ì‘ë‹µ ë¡œê¹…"""
        messages = response.get("messages", [])
        logger.info(f"ğŸ“¤ ëª¨ë¸ ì‘ë‹µ ì™„ë£Œ: {len(messages)}ê°œ ë©”ì‹œì§€")
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ë‚´ìš© ë¡œê¹…
        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]
        if ai_messages:
            last_ai_msg = ai_messages[-1]
            content_preview = str(last_ai_msg.content)[:200] + "..." if len(str(last_ai_msg.content)) > 200 else str(last_ai_msg.content)
            logger.info(f"ğŸ¤– AI ì‘ë‹µ: {content_preview}")
            
            # Tool calls í™•ì¸
            if hasattr(last_ai_msg, 'tool_calls') and last_ai_msg.tool_calls:
                tool_names = [tc.get('name', 'Unknown') for tc in last_ai_msg.tool_calls]
                logger.info(f"ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ ì˜ˆì •: {tool_names}")
    
    def _normalize_content(self, content: Any) -> str:
        """ë©”ì‹œì§€ ë‚´ìš© ì •ê·œí™”"""
        if content is None:
            return ""
        
        if isinstance(content, list):
            return "".join(str(item) for item in content)
        
        return str(content)
    
    def _generate_comprehensive_final_analysis(self, state: AgentState, current_step: int, max_iterations: int) -> str:
        """ì¢…í•©ì ì¸ ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        logger.info("ğŸ“ ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì‹œì‘")
        
        # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        index_id = state.get('index_id', 'Unknown')
        document_id = state.get('document_id', 'Unknown')
        user_query = state.get('user_query', '')
        
        # ë¶„ì„ íˆìŠ¤í† ë¦¬ì™€ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        analysis_history = state.get('analysis_history', [])
        combined_context = state.get('combined_analysis_context', '')
        
        # ì‚¬ìš©ëœ ë„êµ¬ë“¤ ìš”ì•½
        tools_used = []
        successful_analyses = []
        
        for entry in analysis_history:
            tool_name = entry.get('tool_name', 'Unknown')
            success = entry.get('success', False)
            result = entry.get('result', '')
            
            if tool_name not in tools_used:
                tools_used.append(tool_name)
            
            if success and result:
                successful_analyses.append({
                    'tool': tool_name,
                    'result': result[:500] + "..." if len(result) > 500 else result
                })
        
        # ìµœì¢… ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        final_analysis = f"""# ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ ë³´ê³ ì„œ

## ğŸ” ë¶„ì„ ê°œìš”
- **í”„ë¡œì íŠ¸ ID**: {index_id}
- **ë¬¸ì„œ ID**: {document_id}
- **ë¶„ì„ ìš”ì²­**: {user_query[:200]}{"..." if len(user_query) > 200 else ""}
- **ì‹¤í–‰ ë‹¨ê³„**: {current_step}/{max_iterations}
- **ìƒíƒœ**: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ë¡œ ì¸í•œ ë¶„ì„ ì™„ë£Œ

## ğŸ› ï¸ ì‚¬ìš©ëœ ë¶„ì„ ë„êµ¬
"""
        
        if tools_used:
            for tool in tools_used:
                final_analysis += f"- {tool}\n"
        else:
            final_analysis += "- ì‚¬ìš©ëœ ë„êµ¬ ì—†ìŒ\n"
        
        final_analysis += f"""
## ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½

### ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ë¶„ì„ ({len(successful_analyses)}ê±´)
"""
        
        if successful_analyses:
            for i, analysis in enumerate(successful_analyses, 1):
                final_analysis += f"""
#### {i}. {analysis['tool']} ë¶„ì„ ê²°ê³¼
{analysis['result']}
"""
        else:
            final_analysis += "- ì™„ë£Œëœ ë¶„ì„ ê²°ê³¼ ì—†ìŒ\n"
        
        # ì¢…í•© ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° í¬í•¨
        if combined_context and combined_context.strip():
            final_analysis += f"""
## ğŸ”— ì¢…í•© ë¶„ì„ ë‚´ìš©
{combined_context[:1000]}{"..." if len(combined_context) > 1000 else ""}
"""
        
        final_analysis += f"""
## âš ï¸ ë¶„ì„ ì™„ë£Œ ì‚¬ìœ 
ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations})ì— ë„ë‹¬í•˜ì—¬ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. 
ìœ„ì˜ ê²°ê³¼ëŠ” {current_step}ë‹¨ê³„ì— ê±¸ì³ ìˆ˜ì§‘ëœ ëª¨ë“  ë¶„ì„ ì •ë³´ë¥¼ ì¢…í•©í•œ ê²ƒì…ë‹ˆë‹¤.

---
*ë¶„ì„ ì™„ë£Œ ì‹œê°„: {datetime.now(tz=timezone.utc).isoformat()}*
"""
        
        logger.info(f"ğŸ“ ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(final_analysis)} ë¬¸ì")
        logger.info(f"ğŸ“ í¬í•¨ëœ ë¶„ì„ ê²°ê³¼: {len(successful_analyses)}ê±´")
        logger.info(f"ğŸ“ ì‚¬ìš©ëœ ë„êµ¬: {len(tools_used)}ê°œ")
        
        return final_analysis
