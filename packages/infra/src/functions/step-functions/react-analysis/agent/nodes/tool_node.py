"""
LangGraph Tool Node - ë„êµ¬ ì‹¤í–‰ ë‹´ë‹¹
"""

import logging
import time
import os
import sys
from typing import Dict, Any, List, Optional
from langchain_core.tools import BaseTool
from langchain_core.messages import ToolMessage, AIMessage
from langgraph.prebuilt import ToolNode as BaseToolNode

# Common module imports
sys.path.append('/opt/python')
from common import OpenSearchService

from agent.state.agent_state import AgentState
from agent.tools.state_aware_base import StateAwareBaseTool

logger = logging.getLogger(__name__)

BEDROCK_AGENT_MODEL_ID = os.environ.get('BEDROCK_AGENT_MODEL_ID')

def _update_combined_analysis_context(state: AgentState, analysis_history: List[Dict[str, Any]]) -> str:
    """
    ì´ì „ ë¶„ì„ ë‚´ìš©ê³¼ í˜„ì¬ ì„¸ì…˜ ë¶„ì„ ì´ë ¥ì„ ê²°í•©í•´ì„œ combined_analysis_context ìƒì„±
    """
    previous_context = state.get("previous_analysis_context", "")
    
    # ì´ì „ ë¶„ì„ ë‚´ìš©
    context_parts = []
    if previous_context and "ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ" not in previous_context:
        context_parts.append("### ğŸ—‚ï¸ ì´ì „ ì„¸ì…˜ ë¶„ì„ ë‚´ìš©")
        context_parts.append(previous_context)
    
    # í˜„ì¬ ì„¸ì…˜ ë¶„ì„ ì´ë ¥
    if analysis_history:
        context_parts.append(f"\n### ğŸ”„ í˜„ì¬ ì„¸ì…˜ ë¶„ì„ ê²°ê³¼ ({len(analysis_history)}ê°œ):")
        
        for i, entry in enumerate(analysis_history, 1):
            tool_name = entry.get("tool_name", "Unknown")
            content = entry.get("content", "")
            success = entry.get("success", False)
            step = entry.get("step", 0)
            
            status = "âœ…" if success else "âŒ"
            
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
            if len(content) > 1200:
                content_preview = content[:1200] + "...[ìš”ì•½ë¨]"
            else:
                content_preview = content
            
            context_parts.append(f"\n{i}. **{status} {tool_name}** (Step {step}):")
            context_parts.append(f"   {content_preview}")
    
    combined_context = "\n".join(context_parts) if context_parts else "**ë¶„ì„ ë‚´ìš©**: ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
    
    logger.info(f"ğŸ“Š ê²°í•© ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(combined_context)} ë¬¸ì")
    
    return combined_context


class ToolNode:
    """
    LangGraph Tool Node - ë„êµ¬ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ë…¸ë“œ
    StateAware ë„êµ¬ì™€ ì¼ë°˜ ë„êµ¬ë¥¼ ëª¨ë‘ ì§€ì›, OpenSearch ì €ì¥ í¬í•¨
    """
    
    def __init__(self, tools: List[BaseTool]):
        """
        Args:
            tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸
        """
        self.tools = {tool.name: tool for tool in tools}
        self.base_tool_node = BaseToolNode(tools)
        logger.info(f"ğŸ”§ ToolNode ì´ˆê¸°í™” ì™„ë£Œ - ë„êµ¬: {len(tools)}ê°œ")
        
        # OpenSearch ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.opensearch_service = None
        self.enable_opensearch = True
        
        try:
            opensearch_endpoint = os.environ.get('OPENSEARCH_ENDPOINT')
            if opensearch_endpoint:
                self.opensearch_service = OpenSearchService(
                    endpoint=opensearch_endpoint,
                    index_name=os.environ.get('OPENSEARCH_INDEX_NAME', 'aws-idp-ai-analysis'),
                    region=os.environ.get('OPENSEARCH_REGION') or os.environ.get('AWS_REGION', 'us-west-2')
                )
                logger.info("âœ… ToolNode OpenSearch ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("âŒ OPENSEARCH_ENDPOINT í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                self.enable_opensearch = False
        except Exception as e:
            logger.warning(f"âŒ ToolNode OpenSearch ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.enable_opensearch = False
        
        # StateAware ë„êµ¬ ëª©ë¡ ë¡œê¹…
        state_aware_tools = [name for name, tool in self.tools.items() 
                           if isinstance(tool, StateAwareBaseTool)]
        if state_aware_tools:
            logger.info(f"ğŸ“Š StateAware ë„êµ¬: {state_aware_tools}")
    
    def __call__(self, state: AgentState) -> AgentState:
        """
        ë„êµ¬ ë…¸ë“œ ì‹¤í–‰
        
        Args:
            state: LangGraph AgentState
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ AgentState
        """
        logger.info("=== ğŸ”§ TOOL NODE ì‹¤í–‰ ===")
        
        # StateAware ë„êµ¬ë“¤ì— í˜„ì¬ ìƒíƒœ ì„¤ì •
        for tool_name, tool in self.tools.items():
            if isinstance(tool, StateAwareBaseTool):
                object.__setattr__(tool, '_current_state', state)
        
        # ì…ë ¥ ìƒíƒœ ë¡œê¹…
        self._log_input_state(state)
        
        # Tool calls ì¶”ì¶œ
        tool_calls = self._extract_tool_calls(state)
        if not tool_calls:
            logger.warning("âŒ ì‹¤í–‰í•  ë„êµ¬ í˜¸ì¶œì´ ì—†ìŒ")
            return state
        
        # ë„êµ¬ ì‹¤í–‰
        tool_messages, tools_used, tool_results, analysis_history = self._execute_tools(state, tool_calls)
        
        # ì°¸ì¡°ì™€ ì»¨í…ì¸  ì¶”ì¶œ
        tool_references, tool_content = self._extract_references_and_content(tool_results)
        
        # ë¶„ì„ ì´ë ¥ ë° ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        combined_analysis_context = _update_combined_analysis_context(state, analysis_history)
        
        # ì‹¤í–‰ ê²°ê³¼ ë¡œê¹…
        self._log_execution_results(tool_messages, tools_used, analysis_history)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ (ToolNodeëŠ” tool_results, tools_used, analysis_history, combined_analysis_context ë‹´ë‹¹)
        messages = state.get("messages", [])
        updated_state = {
            **state,
            "messages": messages + tool_messages,
            "tools_used": tools_used,
            "tool_results": tool_results,
            "tool_references": tool_references,  # ìƒˆë¡œ ì¶”ê°€
            "tool_content": tool_content,  # ìƒˆë¡œ ì¶”ê°€
            "analysis_history": analysis_history,
            "combined_analysis_context": combined_analysis_context
        }
        
        logger.info(f"ğŸ”§ TOOL NODE ì™„ë£Œ - {len(tool_messages)}ê°œ ë„êµ¬ ì‹¤í–‰")
        return updated_state
    
    def _log_input_state(self, state: AgentState):
        """ì…ë ¥ ìƒíƒœ ë¡œê¹…"""
        messages = state.get("messages", [])
        logger.info(f"ğŸ“¥ ì…ë ¥ - Messages: {len(messages)}ê°œ")
        logger.info(f"ğŸ“¥ ì…ë ¥ - ê¸°ì¡´ ë¶„ì„ ì´ë ¥: {len(state.get('analysis_history', []))}ê°œ")
    
    def _extract_tool_calls(self, state: AgentState) -> List[Dict[str, Any]]:
        """Tool calls ì¶”ì¶œ"""
        messages = state.get("messages", [])
        if not messages:
            return []
            
        last_message = messages[-1]
        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
            return []
        
        tool_calls = last_message.tool_calls
        logger.info(f"ğŸ› ï¸ ì‹¤í–‰í•  ë„êµ¬: {[tc['name'] for tc in tool_calls]}")
        return tool_calls
    
    def _execute_tools(self, state: AgentState, tool_calls: List[Dict[str, Any]]) -> tuple:
        """ë„êµ¬ë“¤ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ë°˜í™˜"""
        tool_messages = []
        tools_used = state.get("tools_used", []).copy()
        tool_results = state.get("tool_results", []).copy()
        analysis_history = state.get("analysis_history", []).copy()
        
        for tool_call in tool_calls:
            tool_name = tool_call["name"]
            tool_args = tool_call["args"]
            tool_call_id = tool_call["id"]
            
            logger.info(f"âš¡ ë„êµ¬ ì‹¤í–‰ ì‹œì‘: {tool_name}")
            logger.info(f"ğŸ“‹ ì…ë ¥ ì¸ì: {self._format_args_for_log(tool_args)}")
            
            # ë„êµ¬ ì‹¤í–‰
            tool_message, success, result_data = self._execute_single_tool(
                state, tool_name, tool_args, tool_call_id
            )
            
            tool_messages.append(tool_message)
            
            # ë„êµ¬ ì‚¬ìš© ì¶”ì 
            if tool_name not in tools_used:
                tools_used.append(tool_name)
            
            # ê²°ê³¼ ì €ì¥ (ì„±ê³µí•œ ê²½ìš°ë§Œ)
            if success and result_data:
                # tool_results ì—…ë°ì´íŠ¸
                tool_result_entry = {
                    "tool_name": tool_name,
                    "success": success,
                    "message": tool_message.content,
                    "data": result_data,
                    "execution_time": result_data.get('execution_time', 0),
                    "timestamp": time.time()
                }
                tool_results.append(tool_result_entry)
                
                # analysis_history ì—…ë°ì´íŠ¸
                analysis_entry = {
                    "tool_name": tool_name,
                    "content": tool_message.content,
                    "success": success,
                    "timestamp": time.time(),
                    "execution_time": result_data.get('execution_time', 0),
                    "step": state.get("current_step", 0)
                }
                analysis_history.append(analysis_entry)
                
                # OpenSearchì— ê²°ê³¼ ì €ì¥ (ì„±ê³µí•œ ê²½ìš°ë§Œ)
                if self.enable_opensearch and self.opensearch_service and success:
                    try:
                        self._save_to_opensearch(state, tool_name, tool_message.content, result_data, tool_args)
                        logger.info(f"ğŸ’¾ {tool_name} OpenSearch ì €ì¥ ì™„ë£Œ")
                    except Exception as e:
                        logger.error(f"âŒ {tool_name} OpenSearch ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                elif success:
                    if not self.enable_opensearch:
                        logger.info(f"âš ï¸ {tool_name} OpenSearch ë¹„í™œì„±í™”ë¡œ ì €ì¥ ê±´ë„ˆëœ€")
                    elif not self.opensearch_service:
                        logger.info(f"âš ï¸ {tool_name} OpenSearch ì„œë¹„ìŠ¤ ì—†ìŒìœ¼ë¡œ ì €ì¥ ê±´ë„ˆëœ€")
                    else:
                        logger.info(f"âš ï¸ {tool_name} ì¡°ê±´ ë¶ˆë§Œì¡±ìœ¼ë¡œ OpenSearch ì €ì¥ ê±´ë„ˆëœ€")
                
                logger.info(f"âœ… {tool_name} ì‹¤í–‰ ì™„ë£Œ - ì´ë ¥ì— ì¶”ê°€ë¨")
            else:
                logger.error(f"âŒ {tool_name} ì‹¤í–‰ ì‹¤íŒ¨")
        
        return tool_messages, tools_used, tool_results, analysis_history
    
    def _execute_single_tool(self, state: AgentState, tool_name: str, tool_args: Dict[str, Any], tool_call_id: str) -> tuple:
        """ë‹¨ì¼ ë„êµ¬ ì‹¤í–‰"""
        tool = self.tools.get(tool_name)
        if not tool:
            error_msg = f"Unknown tool: {tool_name}"
            logger.error(error_msg)
            return ToolMessage(content=error_msg, tool_call_id=tool_call_id), False, None
        
        try:
            start_time = time.time()
            
            # StateAware ë„êµ¬ ì²˜ë¦¬
            if isinstance(tool, StateAwareBaseTool):
                logger.info(f"ğŸ“Š StateAware ë„êµ¬ ì‹¤í–‰: {tool_name}")
                result = tool.execute_with_state(state, **tool_args)
                
                tool_message = ToolMessage(
                    content=result.message,
                    tool_call_id=tool_call_id
                )
                
                result_data = {
                    'execution_time': time.time() - start_time,
                    'data': result.data
                }
                
                return tool_message, result.success, result_data
            
            else:
                # ì¼ë°˜ ë„êµ¬ ì²˜ë¦¬
                logger.info(f"ğŸ”§ ì¼ë°˜ ë„êµ¬ ì‹¤í–‰: {tool_name}")
                
                # ê¸°ë³¸ ToolNode ì‚¬ìš©
                temp_last_message = AIMessage(
                    content="",
                    tool_calls=[{
                        "name": tool_name,
                        "args": tool_args,
                        "id": tool_call_id
                    }]
                )
                temp_state = {
                    **state,
                    "messages": state.get("messages", [])[:-1] + [temp_last_message]
                }
                
                temp_result = self.base_tool_node(temp_state)
                
                # ê²°ê³¼ ì¶”ì¶œ
                if temp_result.get("messages"):
                    new_messages = temp_result["messages"]
                    if new_messages and isinstance(new_messages[-1], ToolMessage):
                        tool_message = new_messages[-1]
                        return tool_message, True, {'execution_time': time.time() - start_time}
                
                # í´ë°±
                return ToolMessage(content="Tool execution completed", tool_call_id=tool_call_id), True, {'execution_time': time.time() - start_time}
                
        except Exception as e:
            error_msg = f"Tool execution failed: {str(e)}"
            logger.error(f"âŒ {tool_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            return ToolMessage(content=error_msg, tool_call_id=tool_call_id), False, None
    
    def _format_args_for_log(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ë¡œê¹…ìš© ì¸ì í¬ë§·íŒ… (ê¸´ ê°’ë“¤ ìš”ì•½)"""
        formatted = {}
        for key, value in args.items():
            if key.startswith('_'):
                formatted[key] = "[Agent Context]"
            elif isinstance(value, str) and len(value) > 100:
                formatted[key] = f"{value[:100]}... ({len(value)} ë¬¸ì)"
            elif isinstance(value, list) and len(value) > 5:
                formatted[key] = f"[ë¦¬ìŠ¤íŠ¸: {len(value)}ê°œ í•­ëª©]"
            else:
                formatted[key] = value
        return formatted
    
    def _log_execution_results(self, tool_messages: List[ToolMessage], tools_used: List[str], analysis_history: List[Dict[str, Any]]):
        """ì‹¤í–‰ ê²°ê³¼ ë¡œê¹…"""
        logger.info(f"ğŸ“¤ ì‹¤í–‰ ì™„ë£Œ - ë©”ì‹œì§€: {len(tool_messages)}ê°œ")
        logger.info(f"ğŸ“¤ ì‹¤í–‰ ì™„ë£Œ - ì‚¬ìš©ëœ ë„êµ¬: {tools_used}")
        logger.info(f"ğŸ“¤ ì‹¤í–‰ ì™„ë£Œ - ì´ ë¶„ì„ ì´ë ¥: {len(analysis_history)}ê°œ")
        
        # ê° ë„êµ¬ ê²°ê³¼ ìš”ì•½ ë¡œê¹…
        for i, msg in enumerate(tool_messages, 1):
            content_preview = msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
            logger.info(f"  {i}. ê²°ê³¼: {content_preview}")
    
    def _save_to_opensearch(self, state: AgentState, tool_name: str, content: str, 
                           result_data: Dict[str, Any], tool_args: Dict[str, Any]) -> None:
        """
        ë„êµ¬ ê²°ê³¼ë¥¼ OpenSearchì— segment-unit ë°©ì‹ìœ¼ë¡œ ì €ì¥
        
        Args:
            state: LangGraph State
            tool_name: ë„êµ¬ ì´ë¦„
            content: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë‚´ìš©
            result_data: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë°ì´í„°
            tool_args: ë„êµ¬ ì‹¤í–‰ ì¸ì
        """
        try:
            # Stateì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            index_id = state.get('index_id')
            document_id = state.get('document_id')
            segment_id = state.get('segment_id')
            segment_index = state.get('segment_index', 0)
            file_path = state.get('file_path', '')
            
            if not document_id:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
                timestamp_ms = int(time.time() * 1000)
                tmp_doc_id = file_path.split("/")[-1].replace(".pdf", "") if file_path else "unknown"
                document_id = f"tool_{tmp_doc_id}_{timestamp_ms}"
                logger.warning(f"document_idê°€ Stateì— ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {document_id}")
            
            if not segment_id:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
                segment_id = f"segment_{document_id}_{segment_index}"
                logger.warning(f"segment_idê°€ Stateì— ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {segment_id}")
            
            # ì‹¤ì œ ì‚¬ìš©ëœ query ì¶”ì¶œ
            analysis_query = None
            
            # result_dataì—ì„œ query ì¶”ì¶œ ì‹œë„
            if result_data and result_data.get('data'):
                data = result_data['data']
                if isinstance(data, dict):
                    analysis_query = data.get('analysis_query')
                    model_version = data.get('model_version')
                    analysis_type = data.get('analysis_type')

            # ë¶„ì„ ë‹¨ê³„ ê²°ì •
            existing_analysis = state.get('analysis_history', [])
            analysis_steps = str(len(existing_analysis) + 1)
            
            # analysis_typeì´ 'skip'ì¸ ê²½ìš° ì €ì¥ ìƒëµ
            if analysis_type == 'skip':
                logger.info("â­ï¸ analysis_type=skip - OpenSearch ì €ì¥ ìƒëµ")
                return

            # Segment-unit ë°©ì‹ìœ¼ë¡œ ai_analysis ë„êµ¬ ì¶”ê°€
            success = self.opensearch_service.add_ai_analysis_tool(
                index_id=index_id,
                segment_id=segment_id,
                document_id=document_id,
                segment_index=segment_index,
                analysis_query=analysis_query,
                content=content,
                analysis_steps=analysis_steps,
                model_version=model_version,
                analysis_type=analysis_type,    
                media_type=state.get('media_type', 'DOCUMENT')
            )
            
            if success:
                logger.info(f"âœ… OpenSearch segment-unit ì €ì¥ ì™„ë£Œ: {tool_name}")
                logger.info(f"ğŸ“Š ì €ì¥ëœ ë°ì´í„°: segment_id={segment_id}, query={analysis_query[:50]}...")
            else:
                logger.error(f"âŒ OpenSearch segment-unit ì €ì¥ ì‹¤íŒ¨: {tool_name}")
            
        except Exception as e:
            logger.error(f"âŒ OpenSearch ì €ì¥ ì‹¤íŒ¨ ({tool_name}): {str(e)}")
            # OpenSearch ì €ì¥ ì‹¤íŒ¨ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ
            pass
    
    def _extract_references_and_content(self, tool_results: List[Dict[str, Any]]) -> tuple:
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ì—ì„œ referencesì™€ content ì¶”ì¶œ"""
        extracted_references = []
        extracted_content_parts = []
        
        logger.info(f"ğŸ” ì°¸ì¡° ë° ì»¨í…ì¸  ì¶”ì¶œ ì‹œì‘ - {len(tool_results)}ê°œ ê²°ê³¼")
        
        for tool_result in tool_results:
            try:
                tool_name = tool_result.get("tool_name", "unknown")
                data = tool_result.get("data", {})
                
                # dataê°€ ë”•ì…”ë„ˆë¦¬ì´ê³  successê°€ Trueì¸ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                if isinstance(data, dict) and data.get("success"):
                    result_data = data.get("data", {})
                    
                    # 1. references ì¶”ì¶œ
                    if "references" in result_data:
                        references = result_data["references"]
                        if isinstance(references, list):
                            for ref in references:
                                if isinstance(ref, str):
                                    # ë¬¸ìì—´ í˜•íƒœì˜ referenceë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                    ref_dict = {
                                        "type": "document",
                                        "title": ref,
                                        "value": ref,
                                        "metadata": {"tool": tool_name, "source": "tool_execution"}
                                    }
                                    extracted_references.append(ref_dict)
                                elif isinstance(ref, dict):
                                    # ì´ë¯¸ êµ¬ì¡°í™”ëœ reference
                                    ref["metadata"] = ref.get("metadata", {})
                                    ref["metadata"]["tool"] = tool_name
                                    ref["metadata"]["source"] = "tool_execution"
                                    extracted_references.append(ref)
                            
                            logger.info(f"ğŸ“‹ {tool_name}ì—ì„œ {len(references)}ê°œ ì°¸ì¡° ì¶”ì¶œ")
                    
                    # 2. content ì¶”ì¶œ
                    if "content" in result_data:
                        content = result_data["content"]
                        if isinstance(content, list):
                            # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° í•­ëª©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
                            for item in content:
                                if item:  # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ
                                    extracted_content_parts.append(str(item))
                        elif isinstance(content, str) and content.strip():
                            # contentê°€ ë¬¸ìì—´ì´ê³  ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°
                            extracted_content_parts.append(content)
                        
                        logger.info(f"ğŸ“ {tool_name}ì—ì„œ ì»¨í…ì¸  ì¶”ì¶œ: {len(str(content))}ì")
                
            except Exception as e:
                logger.error(f"âŒ {tool_result.get('tool_name', 'unknown')} ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        
        # ê²°í•©ëœ ì»¨í…ì¸  ìƒì„±
        combined_content = "\n\n".join(extracted_content_parts) if extracted_content_parts else ""
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ - ì°¸ì¡°: {len(extracted_references)}ê°œ, ì»¨í…ì¸ : {len(combined_content)}ì")
        
        return extracted_references, combined_content