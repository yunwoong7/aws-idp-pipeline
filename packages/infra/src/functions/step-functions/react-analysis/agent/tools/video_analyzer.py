"""
VideoAnalyzerTool - ë™ì˜ìƒ ì±•í„°ë³„ Bedrock AI ë¶„ì„ ë„êµ¬
TwelveLabs Pegasus ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì‹œê°„ êµ¬ê°„ì˜ ë™ì˜ìƒ ë‚´ìš©ì„ ìƒì„¸ ë¶„ì„
"""

import json
import logging
import os
import sys
from typing import Dict, Any, Optional, ClassVar
from pydantic import BaseModel, Field

# Common module imports
sys.path.append('/opt/python')
from common import AWSClientFactory

from .base import BaseTool, ToolResult
from .state_aware_base import StateAwareBaseTool

logger = logging.getLogger(__name__)


class AnalyzeVideoInput(BaseModel):
    """Analyze video using an AI model."""
    query: str = Field(
        title="Analysis Query", 
        description="Question about the information to extract from the video chapter (AI model will analyze this question)"
    )


class VideoAnalyzerTool(StateAwareBaseTool):
    """Video analysis tool with Agent context integration
    Analyze video chapters using TwelveLabs Pegasus model with conversation history context.
    
    Args:
        query: Question about the information to extract from the video chapter
        
    Returns:
        ToolResult: Result of the video chapter analysis
    """
    
    supports_agent_context: ClassVar[bool] = True
    
    def __init__(self):
        super().__init__()
        
        # Use object.__setattr__ to bypass Pydantic field validation for instance attributes
        object.__setattr__(self, 'model_id', os.environ.get('BEDROCK_VIDEO_MODEL_ID', 'us.twelvelabs.pegasus-1-2-v1:0'))
        object.__setattr__(self, 'bucket_owner_id', os.environ.get('BUCKET_OWNER_ACCOUNT_ID', ''))
        
        # Initialize AWS client
        try:
            object.__setattr__(self, 'bedrock_client', AWSClientFactory.get_bedrock_runtime_client())
            logger.info("Bedrock client initialization completed")
        except Exception as e:
            logger.error(f"Failed to initialize Bedrock client: {str(e)}")
            raise
            
        if not self.bucket_owner_id:
            logger.warning("âš ï¸ BUCKET_OWNER_ACCOUNT_ID í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    
    def get_schema(self) -> type:
        return AnalyzeVideoInput

    def _get_agent_context_info(self) -> Dict[str, Any]:
        """Get agent context information (LangGraph State based)"""
        try:
            # Use StateAwareBaseTool's get_agent_context
            agent_context = self.get_agent_context()
            
            # Check if necessary fields exist and set default values
            # Extract conversation_history from State's messages
            conversation_history = []
            if hasattr(self, '_state') and self._state and 'messages' in self._state:
                for msg in self._state['messages']:
                    if hasattr(msg, 'content') and hasattr(msg, '__class__'):
                        msg_type = msg.__class__.__name__
                        if msg_type == 'HumanMessage':
                            conversation_history.append({
                                "role": "user", 
                                "content": str(msg.content)
                            })
                        elif msg_type == 'AIMessage':
                            conversation_history.append({
                                "role": "assistant", 
                                "content": str(msg.content)
                            })
            
            return {
                "index_id": agent_context.get("index_id", "unknown"),
                "document_id": agent_context.get("document_id", "unknown"),
                "segment_id": agent_context.get("segment_id", "unknown"),
                "file_uri": agent_context.get("file_uri") or agent_context.get("file_path"),
                "start_timecode_smpte": agent_context.get("start_timecode_smpte"),
                "end_timecode_smpte": agent_context.get("end_timecode_smpte"),
                "segment_type": agent_context.get("segment_type"),
                "segment_index": agent_context.get("segment_index"),
                "thread_id": agent_context.get("thread_id", "unknown"),
                "user_query": agent_context.get("user_query", ""),
                "session_id": agent_context.get("session_id", ""),
                "conversation_history": conversation_history,
                "previous_analysis_context": agent_context.get("previous_analysis_context", ""),
                "combined_analysis_context": agent_context.get("combined_analysis_context", ""),
                "analysis_history": agent_context.get("analysis_history", []),
                "skip_opensearch_query": agent_context.get("skip_opensearch_query", False)
            }
            
        except Exception as e:
            logger.warning(f"Failed to get agent context: {str(e)}")
            return {
                "index_id": "unknown",
                "document_id": "unknown",
                "segment_id": "unknown",
                "file_uri": None,
                "start_timecode_smpte": None,
                "end_timecode_smpte": None,
                "segment_type": None,
                "segment_index": None,
                "thread_id": "unknown",
                "user_query": "",
                "session_id": "",
                "conversation_history": [],
                "previous_analysis_context": "",
                "combined_analysis_context": "",
                "analysis_history": [],
                "skip_opensearch_query": False,
                "error": f"Failed to get agent context: {str(e)}"
            }

    def execute(self, query: str = None, **kwargs) -> ToolResult:
        """Execute video chapter analysis"""
        try:
            # Get information from Agent context
            agent_context = self._get_agent_context_info()
            document_id = agent_context.get('document_id', 'unknown')
            segment_id = agent_context.get('segment_id', 'unknown')
            file_uri = agent_context.get('file_uri')
            start_timecode = agent_context.get('start_timecode_smpte')
            end_timecode = agent_context.get('end_timecode_smpte')
            segment_type = agent_context.get('segment_type')
            
            logger.info(f"ğŸ¬ Video analysis started")
            logger.info(f"Document ID: {document_id}")
            logger.info(f"Segment ID: {segment_id}")
            logger.info(f"File URI: {file_uri}")
            logger.info(f"Segment Type: {segment_type}")
            logger.info(f"Start Timecode: {start_timecode}")
            logger.info(f"End Timecode: {end_timecode}")
            
            # Debug: Log entire Agent context
            logger.info(f"ğŸ” Agent context contents:")
            for key, value in agent_context.items():
                if key != "tool_registry_instance":
                    logger.info(f"  - {key}: {value}")
            
            # Check if this is a video chapter
            if segment_type != 'CHAPTER':
                logger.info(f"â­ï¸ Skipping non-video segment (type: {segment_type})")
                return self._create_success_result(
                    "ì„¸ê·¸ë¨¼íŠ¸ê°€ ë™ì˜ìƒ ì±•í„°ê°€ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.",
                    {
                        "analysis_type": "skip",
                        "segment_type": segment_type,
                        "segment_id": segment_id,
                        "reason": "Not a video chapter"
                    }
                )
            
            # Validate required information (check for both None and empty string)
            if not all([file_uri and file_uri.strip(), start_timecode and start_timecode.strip(), end_timecode and end_timecode.strip()]):
                missing = []
                if not file_uri or not file_uri.strip(): missing.append('file_uri')
                if not start_timecode or not start_timecode.strip(): missing.append('start_timecode_smpte')
                if not end_timecode or not end_timecode.strip(): missing.append('end_timecode_smpte')
                
                error_msg = f"ë™ì˜ìƒ ë¶„ì„ì— í•„ìš”í•œ ì •ë³´ê°€ ëˆ„ë½ë¨: {missing}"
                logger.error(f"âŒ {error_msg}")
                return self._create_error_result(error_msg)
            
            if not query:
                query = f"ë™ì˜ìƒì˜ {start_timecode}ë¶€í„° {end_timecode}ê¹Œì§€ì˜ êµ¬ê°„ì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”."
            
            # Log query content
            logger.info(f"Video analysis query: {query}")
            
            # Get analysis context (LangGraph State based)
            combined_analysis_context = agent_context.get('combined_analysis_context', '')
            analysis_history = agent_context.get('analysis_history', [])
            
            if combined_analysis_context:
                previous_analysis_context = combined_analysis_context
                logger.info(f"ğŸ” Using combined analysis context: {len(previous_analysis_context)} characters (history {len(analysis_history)} items)")
            else:
                previous_analysis_context = "**Previous analysis context**: No previous analysis results"
                logger.info("ğŸ” No combined analysis context - using default")
            
            # Generate analysis prompt
            analysis_prompt = self._generate_analysis_prompt(
                start_timecode, end_timecode, query, previous_analysis_context
            )
            
            # Analyze video with Bedrock
            analysis_result = self._analyze_video_with_bedrock(file_uri, analysis_prompt)
            
            if not analysis_result:
                return self._create_error_result("Bedrock ë™ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨")
            
            # Return success result
            result_data = {
                "analysis_type": "video_analyzer",
                "segment_id": segment_id,
                "document_id": document_id,
                "file_uri": file_uri,
                "start_timecode_smpte": start_timecode,
                "end_timecode_smpte": end_timecode,
                "query": query,
                "analysis_query": query,  # tool_nodeì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ analysis_queryë¡œë„ ì¶”ê°€
                "ai_response": analysis_result,
                "model_version": self.model_id,
                "token_usage": getattr(self, '_last_token_usage', None)
            }
            
            message = f"ë™ì˜ìƒ ì±•í„° ë¶„ì„ ì™„ë£Œ (ì‹œê°„: {start_timecode} ~ {end_timecode})\n\n{analysis_result}"
            
            logger.info(f"âœ… Video chapter analysis successful: {segment_id}")
            logger.info(f"Analysis result: {analysis_result}")
            
            return self._create_success_result(message, result_data)
            
        except Exception as e:
            error_msg = f"Video analysis failed: {str(e)}"
            logger.error(error_msg)
            return self._create_error_result(error_msg)

    def _generate_analysis_prompt(
        self, 
        start_timecode: str, 
        end_timecode: str,
        query: str,
        previous_analysis_context: str
    ) -> str:
        """
        ì‹œê°„ ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± (í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        """
        # ImageAnalyzerì™€ ìœ ì‚¬í•œ êµ¬ì¡°ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_prompt = f"""
        You are an AI Video Analysis Expert. Analyze the provided video segment and deliver professional insights.

        <analysis_target_segment>{start_timecode} ~ {end_timecode}</analysis_target_segment>
        <previous_analysis_context>{previous_analysis_context}</previous_analysis_context>
        <user_query>{query}</user_query>

        ## Analysis Guidelines:

        **Progressive Strategy**: Build upon previous findings, focus on NEW information not yet covered in the video analysis.

        **Key Priorities**:
        1. Identify visual content and scene composition
        2. Extract audio content (dialogue, narration, sound)
        3. Analyze temporal progression and key moments
        4. Highlight thematic elements and messages

        ## Output Structure:

        1. **Previous Findings Summary** (brief if available)
        2. **New Video Analysis Results**:
        - Visual elements and scene descriptions
        - Audio content and key dialogue
        - Temporal flow and transitions
        - Key insights and themes
        3. **Comprehensive Summary & Recommendations**

        **Focus**: Provide actionable professional insights for the video segment from {start_timecode} to {end_timecode}, avoid redundancy with previous analysis, use appropriate technical terminology for video content analysis.
        """
        
        logger.info(f"ğŸ“ Video analysis prompt generated: {start_timecode} ~ {end_timecode}")
        return user_prompt.strip()

    def _analyze_video_with_bedrock(self, file_uri: str, prompt: str) -> Optional[str]:
        """
        Bedrockì„ ì‚¬ìš©í•œ ë™ì˜ìƒ ë¶„ì„
        """
        try:
            logger.info(f"ğŸ¤– Bedrock ë™ì˜ìƒ ë¶„ì„ ì‹œì‘: {self.model_id}")
            
            # S3 URIì—ì„œ bucketê³¼ key ì¶”ì¶œ
            if not file_uri.startswith('s3://'):
                raise ValueError(f"ì˜ëª»ëœ S3 URI í˜•ì‹: {file_uri}")
            
            # Bedrock ìš”ì²­ ë³¸ë¬¸ êµ¬ì„±
            request_body = {
                "inputPrompt": prompt,
                "mediaSource": {
                    "s3Location": {
                        "uri": file_uri,
                        "bucketOwner": self.bucket_owner_id
                    }
                },
                "temperature": 0
            }
            
            # Bedrock ë™ì˜ìƒ ë¶„ì„ API í˜¸ì¶œ
            response = self.bedrock_client.invoke_model(
                modelId=self.model_id,
                body=json.dumps(request_body),
                contentType="application/json",
                accept="application/json"
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            response_body = json.loads(response['body'].read())
            
            # ì‘ë‹µì—ì„œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ (TwelveLabs ëª¨ë¸ì€ 'message' í•„ë“œ ì‚¬ìš©)
            analysis_result = response_body.get('message', response_body.get('outputText', ''))
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… (í—¤ë” ë˜ëŠ” body.usage)
            try:
                headers = response.get('ResponseMetadata', {}).get('HTTPHeaders', {}) or {}
                input_tokens = headers.get('x-amzn-bedrock-input-token-count')
                output_tokens = headers.get('x-amzn-bedrock-output-token-count')
                total_tokens = headers.get('x-amzn-bedrock-total-token-count')
                if (input_tokens is None or output_tokens is None) and isinstance(response_body, dict) and response_body.get('usage'):
                    usage = response_body['usage']
                    input_tokens = input_tokens or usage.get('input_tokens')
                    output_tokens = output_tokens or usage.get('output_tokens')
                    total_tokens = total_tokens or usage.get('total_tokens')
                logger.info(f"ğŸ”¢ Bedrock Token Usage (video): input={input_tokens}, output={output_tokens}, total={total_tokens}")
                self._last_token_usage = {
                    'input_tokens': int(input_tokens) if input_tokens is not None and str(input_tokens).isdigit() else None,
                    'output_tokens': int(output_tokens) if output_tokens is not None and str(output_tokens).isdigit() else None,
                    'total_tokens': int(total_tokens) if total_tokens is not None and str(total_tokens).isdigit() else None,
                }
            except Exception as token_log_err:
                logger.debug(f"Token usage logging skipped (video): {str(token_log_err)}")
            
            if not analysis_result:
                logger.error("âŒ Bedrock ì‘ë‹µì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                logger.error(f"âŒ ì „ì²´ ì‘ë‹µ: {response_body}")
                return None
            
            logger.info(f"âœ… Bedrock ë™ì˜ìƒ ë¶„ì„ ì™„ë£Œ: {len(analysis_result)} ë¬¸ì")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ Bedrock ë™ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _create_success_result(self, message: str, data: Dict[str, Any], execution_time: float = 0) -> ToolResult:
        """Create success result"""
        return ToolResult(
            success=True,
            message=message,
            data=data,
            execution_time=execution_time
        )
    
    def _create_error_result(self, message: str, execution_time: float = 0) -> ToolResult:
        """Create error result"""
        return ToolResult(
            success=False,
            message=message,
            data=None,
            execution_time=execution_time
        )
